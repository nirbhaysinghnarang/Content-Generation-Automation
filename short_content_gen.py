# -*- coding: utf-8 -*-
"""Short-Content-Gen.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O45nQcEBPp22C2v4aFzYYpgM7IENG62Z
"""

import requests
from PIL import Image
from moviepy.editor import ImageClip, concatenate_videoclips, TextClip, CompositeVideoClip, ImageSequenceClip, AudioFileClip
import io
import numpy as np
import cv2

# Function to generate images using OpenAI's DALL-E API
def generate_images(prompt, num_images=3):
    images = []
    headers = {
        'Authorization': 'your bearer code'
    }
    payload = {
        "prompt": prompt,
        "n": num_images,
        "size": "1024x1024"
    }

    response = requests.post('https://api.openai.com/v1/images/generations', headers=headers, json=payload)
    if response.status_code == 200:
        data = response.json()
        for img_data in data['data']:
            img_bytes = requests.get(img_data['url']).content
            img = Image.open(io.BytesIO(img_bytes))
            images.append(img)
    else:
        print(f"Failed to generate images: {response.text}")
    return images

def put_text_on_image(img, text, font_scale=1, font_thickness=3, text_color=(255, 255, 0)):
    # Calculate the text size to position it at the center
    font = cv2.FONT_HERSHEY_SIMPLEX
    text_size = cv2.getTextSize(text, font, font_scale, font_thickness)[0]

    # Get the center position
    text_x = (img.shape[1] - text_size[0]) / 2
    text_y = (img.shape[0] + text_size[1]) / 2
    position = (int(text_x), int(text_y))

    # Apply bold effect by repeating the text overlay multiple times
    for i in range(3):
        img = cv2.putText(img, text, (position[0] + i, position[1] + i), font, font_scale, text_color, font_thickness, cv2.LINE_AA)

    return img


def create_slideshow(images, story, duration=3):
    # Prepare clips list
    clips = []

    for img in images:
        # Convert PIL image to numpy array
        np_img = np.array(img)

        # Add text onto the image using OpenCV
        np_img_with_text = put_text_on_image(np_img, story)

        # Append the modified image to the clips list
        clips.append(np_img_with_text)

    # Create a clip from image sequences
    clip = ImageSequenceClip(clips, fps=1/duration)

    # Load the background audio
    audio = AudioFileClip('/content/017941_unknown-54945.mp3')

    # Set the audio of the video clip. If the audio is longer than the video, it will be trimmed
    # If the audio is shorter, it will loop
    clip = clip.set_audio(audio.set_duration(clip.duration))

    # Write the clip to a file
    clip.write_videofile("story_with_subtitles_with_music.mp4", fps=24, codec='libx264', audio_codec='aac')



# Main function to generate a short content video
def generate_short_content(prompt):
    # Generate images based on the prompt
    images = generate_images(prompt, num_images=3)


    story ='''कर्मण्येवाधिकारस्ते मा फलेषु कदाचन। मा कर्मफलहेतुर्भूर्मा ते सङ्गोऽस्त्वकर्मणि॥'''

    # Create a slideshow video from the images
    create_slideshow(images, story)

# Example usage
prompt = "Lord Krishna and hindu temples"
generate_short_content(prompt)

